{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_mail_data = pd.read_csv('./mail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will Ã¼ b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(initial_mail_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding: spam=0,ham=1\n",
    "\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the data\n",
    "X = mail_data['Message']\n",
    "\n",
    "Y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the text data to feature vectors to be used as input to the Logistic regression\n",
    "\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "# converting Y_train and Y_test values as integers\n",
    "\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "# training the model with the training data\n",
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data :  0.9670181736594121\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data : ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7287)\t0.21564796138217746\n",
      "  (0, 7277)\t0.20314126795059476\n",
      "  (0, 7274)\t0.22765350956187158\n",
      "  (0, 6976)\t0.17160995712000146\n",
      "  (0, 6638)\t0.21243985558416356\n",
      "  (0, 6556)\t0.20554655054624027\n",
      "  (0, 5740)\t0.2623101226202879\n",
      "  (0, 5560)\t0.17160995712000146\n",
      "  (0, 5241)\t0.5246202452405758\n",
      "  (0, 3267)\t0.18480595042776635\n",
      "  (0, 3104)\t0.29315213357469905\n",
      "  (0, 2923)\t0.29315213357469905\n",
      "  (0, 1438)\t0.29315213357469905\n",
      "  (0, 1326)\t0.27950432631124955\n",
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times\"]\n",
    "\n",
    "# convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "print(input_data_features)\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
